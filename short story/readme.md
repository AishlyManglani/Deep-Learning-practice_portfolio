**Leveraging Large Language Models for Mental Health Detection**

This repository explores the significant potential of Large Language Models (LLMs) in detecting and addressing mental health issues using social media data.

**Overview**

Mental health disorders significantly impact global well-being and productivity. Social media platforms, rich in user-generated content, provide invaluable data to identify mental health disorders early. This project surveys and evaluates how LLMs can harness this data to effectively detect mental health issues.

**Objectives**

- Understand the role and capabilities of LLMs (GPT series, LLaMA, DeepSeek).

- Analyze mental disorders categorized as Emotional Internalization, Psychotic, and Externalizing.

- Evaluate the current state of research, datasets, and metrics in mental health detection.

- Identify future directions and challenges in applying LLMs for mental health detection.


**Case Studies:**

- Depression and Suicide Risk Detection

- Psychotic Disorder Detection (Schizophrenia)

- Externalizing Disorder Detection

**Datasets and Evaluation Metrics**: Overview of datasets (Reddit, Twitter) and evaluation metrics.

**Future Directions**: Integration with personalized interventions, explainable data synthesis, and addressing privacy concerns.

## Key Contributions

Comprehensive review of LLM applications in mental health.

Insightful analysis of classification strategies and model evaluation.

Identification of research gaps and future directions.

## Reference
Medium Article : https://medium.com/@aishly.manglani/leveraging-large-language-models-for-mental-health-detection-9505591052d5


Slideshare Presentation: https://www.slideshare.net/slideshow/leveraging-large-language-models-for-mental-health-detection/278726996


For a detailed survey, refer to the paper:(https://arxiv.org/pdf/2504.02800)

